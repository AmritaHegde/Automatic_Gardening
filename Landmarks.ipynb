{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Landmarks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN52Qcz8p6VBIAdjDxfd+fI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmritaHegde/Automatic_Gardening/blob/master/Landmarks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH9crBhno_KJ"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6hNaK3NpIGF",
        "outputId": "ffafc298-1f7f-4808-a1b3-d1708aa000c4"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zClf7UtOpKxf"
      },
      "source": [
        "from imutils.video import VideoStream\r\n",
        "from imutils import face_utils\r\n",
        "import datetime\r\n",
        "import argparse\r\n",
        "import imutils\r\n",
        "import time\r\n",
        "import dlib\r\n",
        "import cv2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSIKsCccwKLD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gP3LAcGpVK8",
        "outputId": "e2a82059-1332-49ed-c8c9-dff87664a95b"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "%matplotlib inline\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "detector = dlib.get_frontal_face_detector()\r\n",
        "predictor = dlib.shape_predictor(\"/content/drive/My Drive/DeepFake/shape_predictor_68_face_landmarks.dat\")\r\n",
        "\r\n",
        "def face_detection(path):\r\n",
        "  \r\n",
        "  video = cv2.VideoCapture(path)\r\n",
        "  count = 0\r\n",
        "  print(\"[INFO] loading facial landmark predictor...\")\r\n",
        "  \r\n",
        "  while(True):\r\n",
        "    flag,frame = video.read()\r\n",
        "    if(flag):\r\n",
        "      name1 = '/content/drive/My Drive/DeepFake/Frames/frame' + str(count) + '.jpg'\r\n",
        "      name2 = '/content/drive/My Drive/DeepFake/Face/face'+str(count) + '.jpg'\r\n",
        "      \r\n",
        "      \r\n",
        "      cv2.imwrite(name1,frame)\r\n",
        "      pixels = cv2.imread(name1)\r\n",
        "      # Convert image into grayscale\r\n",
        "      gray = cv2.cvtColor(src=pixels, code=cv2.COLOR_BGR2GRAY)\r\n",
        "      faces = detector(gray)\r\n",
        "      for face in faces:\r\n",
        "          x1 = face.left() # left point\r\n",
        "          y1 = face.top() # top point\r\n",
        "          x2 = face.right() # right point\r\n",
        "          y2 = face.bottom() # bottom point\r\n",
        "\r\n",
        "          # Create landmark object\r\n",
        "          landmarks = predictor(image=gray, box=face)\r\n",
        "\r\n",
        "          # Loop through all the points\r\n",
        "          for n in range(0, 68):\r\n",
        "              x = landmarks.part(n).x\r\n",
        "              y = landmarks.part(n).y\r\n",
        "\r\n",
        "              # Draw a circle\r\n",
        "              cv2.circle(img=pixels, center=(x, y), radius=3, color=(0, 255, 0), thickness=-1)\r\n",
        "              cv2.imwrite(name2,pixels) \r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "      \r\n",
        "            \r\n",
        "      \r\n",
        "\r\n",
        "        \r\n",
        "    \r\n",
        "      \r\n",
        "\r\n",
        "      count+=1\r\n",
        "    else:\r\n",
        "      break\r\n",
        "  print(\"Done!\")\r\n",
        "  video.release()\r\n",
        "  cv2.destroyAllWindows()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  path = \"/content/drive/My Drive/DeepFake/DeepfakeTIMIT/higher_quality/fadg0/sa1-video-fram1.avi\"\r\n",
        "  face_detection(path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading facial landmark predictor...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8yN_9j4VFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}